{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3095c155-0e55-447a-b02d-2e0fd28e51ab",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import libraries"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "790f4d66-4c2d-4de9-bc0e-077ac91e6334",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Analyze Silver Tables"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze the three silver tables\n",
    "print(\"=== ANALYZING SILVER TABLES ===\\n\")\n",
    "\n",
    "# 1. Features table\n",
    "print(\"1. FEATURES TABLE\")\n",
    "print(\"-\" * 60)\n",
    "df_features = spark.table(\"practise.silver.features\").filter(col(\"is_current\") == True)\n",
    "print(f\"Total current records: {df_features.count():,}\")\n",
    "print(f\"Date range: {df_features.agg(min('Date'), max('Date')).collect()[0]}\")\n",
    "print(f\"Stores: {df_features.select('Store').distinct().count()}\")\n",
    "print(\"\\nSample data:\")\n",
    "display(df_features.limit(3))\n",
    "\n",
    "# 2. Sales table\n",
    "print(\"\\n2. SALES TABLE\")\n",
    "print(\"-\" * 60)\n",
    "df_sales = spark.table(\"practise.silver.sales\").filter(col(\"is_current\") == True)\n",
    "print(f\"Total current records: {df_sales.count():,}\")\n",
    "print(f\"Date range: {df_sales.agg(min('Date'), max('Date')).collect()[0]}\")\n",
    "print(f\"Stores: {df_sales.select('Store').distinct().count()}\")\n",
    "print(f\"Departments: {df_sales.select('Dept').distinct().count()}\")\n",
    "print(f\"Total Sales: ${df_sales.agg(sum('Weekly_Sales')).collect()[0][0]:,.2f}\")\n",
    "print(\"\\nSample data:\")\n",
    "display(df_sales.limit(3))\n",
    "\n",
    "# 3. Stores table\n",
    "print(\"\\n3. STORES TABLE\")\n",
    "print(\"-\" * 60)\n",
    "df_stores = spark.table(\"practise.silver.stores\").filter(col(\"is_current\") == True)\n",
    "print(f\"Total current records: {df_stores.count():,}\")\n",
    "print(f\"Store Types: {df_stores.select('Type').distinct().collect()}\")\n",
    "print(\"\\nSample data:\")\n",
    "display(df_stores.limit(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7acb7d56-db8c-4d07-80f4-3bd09a9181e6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Gold Table 1: Sales Summary by Store"
    }
   },
   "outputs": [],
   "source": [
    "# Create Gold Table 1: Sales Summary by Store\n",
    "# Aggregates sales data with store information\n",
    "\n",
    "print(\"Creating Gold Table 1: Sales Summary by Store...\\n\")\n",
    "\n",
    "# Join sales with stores to get store details\n",
    "gold_sales_by_store = df_sales \\\n",
    "    .join(df_stores, \"Store\") \\\n",
    "    .groupBy(\"Store\", \"Type\", \"Size\") \\\n",
    "    .agg(\n",
    "        sum(\"Weekly_Sales\").alias(\"Total_Sales\"),\n",
    "        avg(\"Weekly_Sales\").alias(\"Avg_Weekly_Sales\"),\n",
    "        count(\"*\").alias(\"Total_Weeks\"),\n",
    "        countDistinct(\"Dept\").alias(\"Num_Departments\"),\n",
    "        sum(when(col(\"IsHoliday\") == True, col(\"Weekly_Sales\")).otherwise(0)).alias(\"Holiday_Sales\"),\n",
    "        sum(when(col(\"IsHoliday\") == False, col(\"Weekly_Sales\")).otherwise(0)).alias(\"Non_Holiday_Sales\")\n",
    "    ) \\\n",
    "    .withColumn(\"Sales_Per_SqFt\", col(\"Total_Sales\") / col(\"Size\")) \\\n",
    "    .withColumn(\"Holiday_Sales_Pct\", (col(\"Holiday_Sales\") / col(\"Total_Sales\")) * 100) \\\n",
    "    .orderBy(col(\"Total_Sales\").desc())\n",
    "\n",
    "# Save to gold layer\n",
    "if not spark.catalog.tableExists(\"practise.gold.sales_by_store\"):\n",
    "    gold_sales_by_store.write.format(\"delta\").saveAsTable(\"practise.gold.sales_by_store\")\n",
    "    print(\"✅ Created: practise.gold.sales_by_store\")\n",
    "else:\n",
    "    print(\"⚠️  Table already exists: practise.gold.sales_by_store\")\n",
    "    print(\"   Run this to recreate: spark.sql('DROP TABLE practise.gold.sales_by_store')\")\n",
    "\n",
    "print(f\"Records: {gold_sales_by_store.count():,}\\n\")\n",
    "print(\"Top 5 stores by sales:\")\n",
    "display(gold_sales_by_store.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e32df95-0e29-496f-9405-0e429b9316a6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Gold Table 2: Sales Trends Over Time"
    }
   },
   "outputs": [],
   "source": [
    "# Create Gold Table 2: Sales Trends Over Time\n",
    "# Time-based aggregations for trend analysis\n",
    "\n",
    "print(\"Creating Gold Table 2: Sales Trends Over Time...\\n\")\n",
    "\n",
    "gold_sales_trends = df_sales \\\n",
    "    .withColumn(\"Year\", year(\"Date\")) \\\n",
    "    .withColumn(\"Month\", month(\"Date\")) \\\n",
    "    .withColumn(\"Week\", weekofyear(\"Date\")) \\\n",
    "    .withColumn(\"Quarter\", quarter(\"Date\")) \\\n",
    "    .groupBy(\"Year\", \"Quarter\", \"Month\", \"Week\", \"Date\", \"IsHoliday\") \\\n",
    "    .agg(\n",
    "        sum(\"Weekly_Sales\").alias(\"Total_Sales\"),\n",
    "        avg(\"Weekly_Sales\").alias(\"Avg_Sales\"),\n",
    "        count(\"*\").alias(\"Num_Transactions\"),\n",
    "        countDistinct(\"Store\").alias(\"Num_Stores\"),\n",
    "        countDistinct(\"Dept\").alias(\"Num_Departments\")\n",
    "    ) \\\n",
    "    .orderBy(\"Date\")\n",
    "\n",
    "# Save to gold layer\n",
    "if not spark.catalog.tableExists(\"practise.gold.sales_trends\"):\n",
    "    gold_sales_trends.write.format(\"delta\").saveAsTable(\"practise.gold.sales_trends\")\n",
    "    print(\"✅ Created: practise.gold.sales_trends\")\n",
    "else:\n",
    "    print(\"⚠️  Table already exists: practise.gold.sales_trends\")\n",
    "\n",
    "print(f\"Records: {gold_sales_trends.count():,}\\n\")\n",
    "print(\"Sample trends:\")\n",
    "display(gold_sales_trends.limit(5))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "To_Gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
